window.DEFAULT_QUESTIONS_VISUAL = [
  {
    "role": "visual",
    "dimension": "维度三：影响他人对AI的重视程度",
    "question": "题目描述\n公司品牌部一直认为 AI 生成的“国潮插画”缺乏灵魂，细节充满了“由于数据污染导致的刻板印象”（如奇怪的汉字、日式灯笼等），因此要求设计师进行纯手绘，导致项目严重延期。为了消除偏见并推动 AI 在品牌设计中的合规应用，以下哪种做法最具建设性？",
    "options": [
      {
        "id": "A",
        "text": "在周会上展示 即梦 (Jimeng)的底层扩散模型数学公式，详细讲解 Latent Space (潜空间) 的降噪原理，从理论物理的高度证明 AI 生成的随机性是可以被数学收敛的，以此说服品牌总监。"
      },
      {
        "id": "B",
        "text": "组织一场“AI 风格控制”内部分享会，演示如何利用即梦 (Jimeng)的“参考图控制”锁定二次元画风。"
      },
      {
        "id": "C",
        "text": "上传 品牌部门VI 手册到即梦 (Jimeng)，AI 就能在生成过程中实时进行“合规审查”，修正细节。"
      },
      {
        "id": "D",
        "text": "抽调需求外的时间，配合技术团队采集1万张内部手绘图，利用Coze (扣子)训练一个完全私有化的“洋葱大模型”，来满足商用需求。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确 - 实证推广)：D3 维度的核心是用事实打破偏见。面对“AI 不可控”的质疑，空谈理论无效，必须通过“现场演示”展示具体的控制手段（如参考图、负向提示词），让业务方亲眼看到 AI 是可以在规范内戴着镣铐跳舞的，从而建立信任。\nA (错误 - 理论脱离实际)：设计师不是科学家，向美术/品牌人员讲解枯燥的数学公式和底层原理，不仅无法解决具体的“画风跑偏”问题，反而会增加对方的认知负担和抵触情绪。\nC (错误 - 功能幻觉)：即梦并没有所谓的“自动上传 VI 手册进行实时合规审查”的功能。\nD (错误 - 效率陷阱)：在项目延期的背景下，提出耗时数月的“私有模型训练”计划是远水解不了近渴，且对于常规插画需求，过度追求私有化训练属于投入产出比极低的过度工程化。",
    "type": "single",
    "id": "visual-single-1769587483379-31062-5"
  },
  {
    "role": "visual",
    "dimension": "维度三：影响他人对AI的重视程度",
    "question": "题目描述\n运营团队策划了“洋葱学园百日誓师”活动，未来 100 天每天都要发布一张针对不同学科（如数学几何、物理力学）的倒计时海报，且文案每日更新。面对这一高频重复需求，作为视觉设计师，以下哪种解决方案既能高效完成任务，又能最大程度提升团队对 AI 降本增效价值的认可？",
    "options": [
      {
        "id": "A",
        "text": "在 Coze (扣子) 中搭建一个“百日誓师海报生成体”，通过 WorkFlow 串联文生图模型生成学科背景，结合代码节点自动处理文字排版，一键出图。"
      },
      {
        "id": "B",
        "text": "利用 Midjourney 批量生成 100 张高质量的通用背景图，导入 Photoshop 建立智能对象模板，自己每天定时替换文案并导出，确保海报的审美都由设计师亲自把控。"
      },
      {
        "id": "C",
        "text": "在团队周会上展示一张极度复杂的 ComfyUI 节点连线图，讲解ai的高技术门槛，详细讲解如何通过 ControlNet 和 IP-Adapter 实现海报的自动化生成。"
      },
      {
        "id": "D",
        "text": "利用 Coze Bot 最新接入了的“矢量逆向引擎”，不仅能生成海报，还能输出可编辑的分层文件"
      }
    ],
    "correct": [
      "A"
    ],
    "explanation": "\nA (正确 - 工具赋能)：D3 维度的最高境界是“授人以渔”。通过 Coze 将复杂的 AI 能力封装成“傻瓜式”的 Bot 工具并交付给下游（运营）使用，不仅彻底解决了设计团队的重复劳动，更让业务方亲身体验到 AI 带来的效率革命，是极具影响力的 AI 推广行为。\nB (错误 - 个人提效)：虽然利用 MJ 提升了素材生产效率，但依然保留了“设计师手动改字”的环节，且属于“黑盒交付”，团队感知不到 AI 的价值，只会觉得你手速快。\nC (错误 - 炫技门槛)：向非技术人员展示过于复杂的 ComfyUI 节点（意大利面条式连线）往往会产生反效果，让人觉得“AI 太难了、门槛太高”，反而阻碍了 AI 在团队内的普及和应用。\nD (错误 - 功能幻觉)：coze无法生成海报分层文件",
    "type": "single",
    "id": "visual-single-1769587483379-14449-4"
  },
  {
    "role": "visual",
    "dimension": "维度八：AI结果辨别和优化能力",
    "question": "你要为洋葱官网作一张等距视角(Isometric)风格的未来自习室插画。画面要求：透明玻璃墙体、充满科技感的悬浮桌椅、画面中央的空中全息屏幕上显示洋葱学园logo。你使用即梦生成了一张底图，整体氛围很棒，但仔细审查发现存在两个问题：1.品牌资产错误：全息屏幕上的 Logo 虽然也是个洋葱，但形状、线条与公司标准不符。2.悬浮椅子的透视角度与桌子不一致，看起来像贴上去的。3.玻璃墙体的折射光影复杂，导致背景杂乱。以下哪种优化策略是最高效且可落地的？",
    "options": [
      {
        "id": "A",
        "text": "优化提示词：在提示词中增加 “logo细节描述，完美透视角度、悬浮椅子的透视角度要和桌子保持一致，极简玻璃背景”并将权重设为最高，重复生成 10 次，选取完美结果。"
      },
      {
        "id": "B",
        "text": "在 PS 中处理 Logo 角度及发光效果，使用即梦的“局部重绘 ”单独修正椅子透视，背景在PS模糊处理，解决杂乱。"
      },
      {
        "id": "C",
        "text": "使用即梦“高清放大 (Upscale)”功能，选择“创意重绘”模式。在放大重绘制过程中，自动优化logo边缘线条，完善细节，同时修复椅子的透视问题。"
      },
      {
        "id": "D",
        "text": "将洋葱学园 Logo 设为参考图，把重绘幅度开到 1.0，让 AI 把全息屏幕区域重绘成标准 Logo，同步优化透视角度。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确 - 辨别与组合拳)：本题考察的是对商用交付标准的判断。\nA (错误 - 抽卡赌博)：Prompt 只能控制“语义类型”（画一个洋葱），无法控制“拓扑结构”（画出那个特定的洋葱）。试图通过文字描述还原矢量级 Logo 是不可能的。\nC (错误 - 技术幻觉)：Upscale 的作用是增加细节像素，它不会改变画面的语义内容。它会让错误的 Logo 变得更清晰，而不会把它变成对的 Logo。\nD (错误 - 操作不可控)：虽然用了参考图，但在复杂的 3D 场景中，强行高重绘幅度往往会导致 Logo 风格与画面格格不入（比如变成扁平矢量图贴在 3D 屏幕上），或者严重破坏原有的光影氛围。",
    "type": "single",
    "id": "visual-single-1769587483379-33675-15"
  },
  {
    "role": "visual",
    "dimension": "维度八：AI结果辨别和优化能力",
    "question": "题目描述：\n你正在为洋葱学园的“开学季”活动设计主视觉，使用国产 AI 工具 即梦 (Jimeng) 生成了一张“二次元洋葱君抱着书本奔跑”的 3D 插画。整体动态很棒，但仔细检查发现，书皮上的“洋葱数学”四个字是扭曲的火星文，且洋葱君的左脚鞋带结构模糊不清。此时，展现你专业辨别与优化能力的最佳做法是？",
    "options": [
      {
        "id": "A",
        "text": "利用“变化” (Variation) 功能抽卡：将该图作为垫图，在即梦中选择“强变化”模式，在提示词中强调“写实文字，完美鞋带”"
      },
      {
        "id": "B",
        "text": "识别出品牌资产（文字）必须精确还原，结构细节（鞋带）可用 AI 修复。将图片在 即梦 中使用“局部重绘”修复鞋带结构；同时涂抹掉书皮文字区域，导出后在MasterGo中利用透视插件贴入标准的矢量 LOGO，确保品牌一致性。"
      },
      {
        "id": "C",
        "text": "在 即梦 中不断调整提示词，增加 \"perfect text, clear shoelaces\" 等关键词，重复生成 50 次，直到出现一张文字正确且细节完美的图片。"
      },
      {
        "id": "D",
        "text": "把图片直接发给 豆包 (Doubao)对话框，输入指令：“请帮我把图里的字改对，把鞋带修好”，期待它直接返回一张图层分明、细节完美的修复图。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确)：体现了“裁判员”的辨别能力（区分哪些AI能修，哪些必须人工做）。对于品牌文字/LOGO，AI 生成极易出错（即梦目前也无法生成完美指定汉字），最优解是“AI 修复光影/结构 + 人工合成矢量资产”的混合工作流。\nA (错误 - 随机性陷阱)：Variation 功能会改变画面的整体构图和细节，且极难精准修正具体的汉字错误，这属于“试图用随机性解决确定性问题”的错误思路。\nC (错误 - 抽卡思维)：对于具体汉字生成，目前 AI（即使是国产）的成功率极低，反复抽卡是极度低效的行为。\nD (错误 - 工具能力幻觉)：虽然豆包等多模态 AI 具备修图能力，但对于“保持原图光影不变仅替换特定品牌字”这种精细设计需求，对话式 AI 往往难以达到生产级精度，且无法提供图层编辑。",
    "type": "single",
    "id": "visual-single-1769587483379-85081-14"
  },
  {
    "role": "visual",
    "dimension": "维度二：AI 发展趋势了解度",
    "question": "题目描述\n洋葱学园计划开发一款针对少儿的互动绘本 App，需要大量风格统一且动作连续的角色插图。关于当前 AI 技术在“一致性与连续性”方面的能力，以下哪些判断是准确的？",
    "options": [
      {
        "id": "A",
        "text": "Midjourney v6 的 --cref (Character Reference) 参数可以有效保持角色的面部特征，适合生成同一角色的不同动作。"
      },
      {
        "id": "B",
        "text": "Stable Diffusion 配合 ControlNet (OpenPose + Canny) 是目前控制角色骨架姿势和线稿细节最精准的方案。"
      },
      {
        "id": "C",
        "text": "目前的 AI 视频模型（如 Runway Gen-3, Luma Dream Machine）已经可以完美生成长达 10 分钟且剧情连贯、角色完全不崩坏的动画短片，可以直接替代绘本开发。"
      },
      {
        "id": "D",
        "text": "针对简单的 2D 骨骼动画，可以使用 AI 工具将静态插图自动拆分部件并生成骨骼绑定信息（如 Animated Drawings 或类似工具），辅助动效制作。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B, D (正确)：准确评估了 MJ 和 SD 在角色一致性控制上的优势，以及 AI 在辅助动效制作上的单点能力。\nC (陷阱 - 夸大趋势)：目前的 AI 视频模型通常只能生成几秒钟的高质量片段，无法一次性生成长时长、强逻辑、角色绝对稳定的动画长片，属于对技术成熟度的误判。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-13718-2"
  },
  {
    "role": "visual",
    "dimension": "维度二：AI 发展趋势了解度",
    "question": "题目描述\n随着 AI 技术的迭代，设计师的交付标准也在发生变化。关于“AI 时代的视觉交付”，以下哪些观点符合当前的技术趋势？",
    "options": [
      {
        "id": "A",
        "text": "交付物不再局限于静态图片，设计师应掌握用 AI 生成动态 Cinemagraph 或短视频（如用 Runway 让海报动起来）的能力。"
      },
      {
        "id": "B",
        "text": "“可编辑性”依然重要，不能只交付一张扁平的 JPG，应利用 AI 辅助生成的素材进行分层合成，保留 PSD 的图层逻辑。"
      },
      {
        "id": "C",
        "text": "3D 资产的生成门槛正在降低，平面设计师未来应具备使用 AI 生成 3D 模型（obj/glb）并进行简单贴图渲染的能力。"
      },
      {
        "id": "D",
        "text": "因为 AI 可以无限生成，所以设计师不需要再维护设计规范系统 (Design System)，每次需要时直接让 AI 随机生成即可。"
      }
    ],
    "correct": [
      "A",
      "B",
      "C"
    ],
    "explanation": "\nA, B, C (正确)：分别涵盖了“动态化”、“工程化（分层）”和“三维化”的三个重要趋势。\nD (陷阱 - 逻辑谬误)：越是 AI 时代，越需要设计规范来约束 AI 的随机性，确保品牌一致性，放弃规范会导致品牌视觉崩塌。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-38763-3"
  },
  {
    "role": "visual",
    "dimension": "维度四：会几个AI工具",
    "question": "题目描述\n你需要为洋葱学园的吉祥物制作一套“情绪表情包”，已经有一张完美的主形象图。现在需要生成“大哭”和“大笑”的表情，且必须严格保持角色的五官特征不变。生成中，最核心的操作是？",
    "options": [
      {
        "id": "A",
        "text": "使用 Midjourney 在提示词中详细描述角色的每一个特征（蓝头发、圆眼镜、黄色连帽衫），并添加 --seed 参数固定随机种子。"
      },
      {
        "id": "B",
        "text": "使用 即梦 (Jimeng) 在“参考图”区域上传原图，选择“人物特征 (Character)”模式，通过控制权重锁定五官结构，再通过提示词修改表情。"
      },
      {
        "id": "C",
        "text": "使用 即梦 (Jimeng) 在“参考图”区域上传原图，选择“风格参考 (Style)”模式，认为这样就能识别出角色的长相并保持不变。"
      },
      {
        "id": "D",
        "text": "使用 Midjourney  /blend 指令，将原图和一张真人大笑的照片混合，希望 AI 能自动提取角色的脸和真人的表情。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB 正确 - 工具专精\nA 错误 - 参数误用：--seed 只能在 Prompt 完全一致时保证结果一致，一旦修改 Prompt（改表情），Seed 无法锁定长相。\nC 错误，功能幻觉，风格参考不用锁定角色形象\nD 错误 - 效果不可控：Blend 主要是混合构图和概念，极大概率会弄丢原角色的特征，变成一个奇怪的混合体。",
    "type": "single",
    "id": "visual-single-1769587483379-77936-6"
  },
  {
    "role": "visual",
    "dimension": "维度四：会几个AI工具",
    "question": "题目描述\n你在制作一张横版 Banner 时，发现素材图（人物半身像）左右两侧背景不够长，无法填满画面。以下哪个 AI 工具流能最完美地实现“无损向外扩展背景”？",
    "options": [
      {
        "id": "A",
        "text": "使用 Photoshop 的“内容识别填充 (Content-Aware Fill)”，框选空白区域进行计算填充。"
      },
      {
        "id": "B",
        "text": "将图片导入即梦 (Jimeng)，使用“智能扩图” (Outpainting功能，设定目标比例（如 16:9），并通过提示词控制背景元素（如“科技感办公室、景深”），让 AI 自动生成缺失的两侧画面并保持光影连贯。"
      },
      {
        "id": "C",
        "text": "将图片上传到 Midjourney，使用 `/describe` 指令试图反推原图的提示词，然后重新生成一张构图更宽的新图，但这会导致原图的人物特征（Face ID）完全改变。"
      },
      {
        "id": "D",
        "text": "使用 Topaz Gigapixel AI 将图片放大 4 倍，然后直接截取需要的部分，通过强行拉伸像素来填满背景。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确 - 场景匹配)：即梦 (Jimeng) 的“智能扩图”是专门针对构图补全场景的生成式工具，相比传统工具，它能理解画面语义，自动生成不存在的背景细节，且操作门槛低，是处理此类需求的首选国产工具。\nA (陷阱 - 过时技术)：内容识别填充是基于像素采样的传统算法，对于复杂背景容易出现重复纹理和明显的接缝，不如生成式 AI 自然。\nC (陷阱 - 工具误用)：`/describe` 是用于反推提示词的，无法进行扩图操作。即使重绘，MJ 在保持原图人物特征上极其困难，不符合“无损扩展”的要求。\nD (陷阱 - 功能混淆)：Topaz 是用来提升画质/清晰度的“放大”工具，无法“无中生有”生成缺失的背景内容。",
    "type": "single",
    "id": "visual-single-1769587483379-16950-7"
  },
  {
    "role": "visual",
    "dimension": "维度六：利用AI赋能团队的能力",
    "question": "题目描述\n设计团队积累了大量过往的优质设计资产（海报、插画、ICON），但查找复用很困难。作为 AI 专家，以下哪些方案能赋能团队资产管理？",
    "options": [
      {
        "id": "A",
        "text": "利用 Eagle 或 Billfish 等素材管理工具的“AI 标签/智能分类”功能，自动识别图片内容（如颜色、对象、风格）并打标，方便检索。"
      },
      {
        "id": "B",
        "text": "训练一个团队专属的 Stable Diffusion Checkpoint 或 LoRA 模型，将过往的优质美术风格固化下来，供全员调用生成新图。"
      },
      {
        "id": "C",
        "text": "建立一个共享文件夹，把所有文件堆进去，让大家用肉眼一张张看。"
      },
      {
        "id": "D",
        "text": "搭建一个内部的 Prompt 库（如使用 Notion 或飞书多维表格），将生成过往优质图片的参数、Seed 值和对应原图关联起来，方便一键复用。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B, D (正确)：分别从“智能检索”、“风格固化（模型化）”和“参数资产化”三个维度提升了团队的资产复用效率。\nC (陷阱 - 原始低效)：没有任何 AI 或技术赋能，不仅没提效，随着资产增加反而会降低效率。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-16880-10"
  },
  {
    "role": "visual",
    "dimension": "维度六：利用AI赋能团队的能力",
    "question": "题目描述\n为了应对双十一大促，运营每天需要更换 50 张不同商品的 Banner，版式固定但商品图和文案不同。如何构建 AI 工作流来赋能团队解决此问题？",
    "options": [
      {
        "id": "A",
        "text": "安排 5 个实习生，每人每天负责做 10 张，手动替换图片和文字。"
      },
      {
        "id": "B",
        "text": "使用 Photoshop 的“变量”功能结合数据组，虽然是传统功能，但结合 AI 生成的去底商品图，能极大提升效率。"
      },
      {
        "id": "C",
        "text": "利用 ComfyUI 搭建自动化工作流：输入商品图 -> 自动抠图 (Rembg) -> 自动匹配背景 (IPAdapter) -> 自动排版文字 -> 输出成品。"
      },
      {
        "id": "D",
        "text": "使用 Figma 的 AI 插件（如 Automator 或专用的批量生成插件），读取 Excel 表格中的文案和图片链接，一键批量填充生成设计稿。"
      }
    ],
    "correct": [
      "B",
      "C",
      "D"
    ],
    "explanation": "\nB, C, D (正确)：B 是传统自动化+AI素材，C 是高阶 AI 全流程自动化，D 是 UI 设计工具的自动化，都是解决批量化需求的有效手段。\nA (陷阱 - 堆人力)：最原始的人海战术，完全没有体现 AI 赋能团队的价值。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-58850-11"
  },
  {
    "role": "visual",
    "dimension": "维度二：AI 发展趋势了解度",
    "question": "题目描述\n业务团队需要制作一系列赛博朋克风格的 3D 盲盒海报，核心要求是画面中央必须赫然显示正确的英文单词 \"ONION FUTURE\"，且文字材质需要与周围环境的光影完美融合（如霓虹反光）。在 2024-2025 年的 AI 技术变革背景下，以下哪种模型选型策略体现了对最新 AI 架构趋势的深刻理解？",
    "options": [
      {
        "id": "A",
        "text": "打开即梦 (Jimeng)，上传一张黑底白字的文字排版图作为“参考图”，将“重绘幅度” (Denoising Strength) 设置为 0.3，通过“图生图”的方式在保留文字形状的同时让 AI 自动添加霓虹光影细节。"
      },
      {
        "id": "B",
        "text": "Stable Diffusion 1.5配合 ControlNet (Canny/Depth)。虽然模型较旧，但截止目前，它依然是行业内唯一能生成可读文字的 AI 模型，新出的模型为了追求画质都牺牲了文字生成能力。"
      },
      {
        "id": "C",
        "text": "优先选择基于Diffusion Transformer架构的新一代模型（如 FLUX.1）。这类模型相比传统的 UNet 架构，在语义理解和“文字拼写生成”能力上有代际级的提升。"
      },
      {
        "id": "D",
        "text": "将需求发送给 豆包 (Doubao)或 GPT-4o，指令其直接生成 \".obj\" 或 \".gltf\" 格式的 3D 源文件，因为最新的多模态大模型已经彻底取代了平面渲染，直接产出三维模型才是当前的主流趋势。"
      }
    ],
    "correct": [
      "C"
    ],
    "explanation": "\nC (正确 - 趋势认知)：考察对 AI 底层架构迭代（UNet -> DiT）的了解。目前 FLUX.1 等基于 Transformer 的模型解决了旧模型“不识字”的痛点，是当前处理“图内文字”的最优趋势。\nA (错误 - 参数陷阱/旧思路)：虽然即梦很强，但在“重绘幅度 0.3”的低参数下，AI 几乎不会改变原图的材质（黑底白字依然会是黑底白字）；如果调高幅度，文字形状又会崩坏。这种“图生图硬转”是旧版本 AI 的妥协做法，不如使用原生支持文字生成的 DiT 模型高效。\nB (错误 - 认知滞后)：典型的经验主义错误。虽然 ControlNet 曾是王者，但认为“新模型无法生成文字”完全违背了技术事实（新模型反而更擅长文字）。\nD (错误 - 盲目超前/幻觉)：虽然 3D 生成是趋势，但目前的商用模型生成的 3D 拓扑结构和贴图精度尚无法直接用于高精海报的主视觉输出。",
    "type": "single",
    "id": "visual-single-1769587483379-40212-2"
  },
  {
    "role": "visual",
    "dimension": "维度二：AI 发展趋势了解度",
    "question": "题目描述\n老板听说现在 AI 很火，要求你以后输出的所有二次元角色插图必须是“矢量的 (Vector)”，以便印刷在巨幅户外广告上不失真。以下关于 AI 矢量生成能力的判断，哪项是符合当前技术现状的？",
    "options": [
      {
        "id": "A",
        "text": "目前 Midjourney 和即梦原生生成的都是位图，虽然有插件可转矢量但细节损失大，建议使用 Recraft 或 Illustrator 的 Text to Vector 功能生成矢量图。"
      },
      {
        "id": "B",
        "text": "直接在 Midjourney 的提示词后加上 “--vector” 或 “--svg” 参数，即可直接导出高质量的 AI 矢量源文件。"
      },
      {
        "id": "C",
        "text": "告诉老板 AI 目前只能生成位图，无法生成矢量图，必须全部由设计师在 Illustrator 中用钢笔工具手工绘制。"
      },
      {
        "id": "D",
        "text": "先用 Midjourney 生成高清位图，然后放入 Photoshop 中，点击“图像大小”将分辨率改为 300dpi，即可转化为矢量图。"
      }
    ],
    "correct": [
      "A"
    ],
    "explanation": "\nA (正确 - 边界认知)：清晰地知道主流生成式 AI（MJ/SD）的局限性（位图），同时了解专注于矢量生成的新工具（Recraft/Adobe Firefly Vector），给出了专业的技术选型。\nB (陷阱 - 伪参数)：Midjourney 不存在 “--vector” 这种能直接改变文件底层属性的参数，这是典型的指令幻觉。\nC (陷阱 - 认知滞后)：否认了 AI 在矢量领域的进展，Adobe Firefly 和 Recraft 等工具已经具备了较好的矢量生成能力。\nD (陷阱 - 概念混淆)：修改分辨率 (dpi) 只是增加了像素密度，并不能将位图转为数学公式描述的矢量图，属于基础概念错误。",
    "type": "single",
    "id": "visual-single-1769587483379-18714-3"
  },
  {
    "role": "visual",
    "dimension": "维度八：AI结果辨别和优化能力",
    "question": "题目描述\n在使用 Midjourney 生成“二次元少女在图书馆看书”的图片时，你发现画面存在一些不易察觉的逻辑错误和瑕疵。作为专业设计师，你应该敏锐地识别并修复以下哪些问题？",
    "options": [
      {
        "id": "A",
        "text": "书本上的文字是乱码或类似希伯来文的符号，需要用 PS 替换为清晰可读的书名。"
      },
      {
        "id": "B",
        "text": "人物的眼镜框在左边有，在右边消失了，或者镜腿插入了鬓角里，需要重绘修复。"
      },
      {
        "id": "C",
        "text": "画面背景的光源在左侧，但人物面部的阴影却在左侧（光影冲突），需要调整光影逻辑。"
      },
      {
        "id": "D",
        "text": "衣服上的纽扣大小不一且排列歪斜，不符合物理规律，需要修整。"
      }
    ],
    "correct": [
      "A",
      "B",
      "C",
      "D"
    ],
    "explanation": "\nA, B, C, D (正确)：全选。这四个选项（文字乱码、结构错误、光影逻辑、细节物理常识）都是 AI 生成图目前最常见且必须修复的“一眼假”硬伤，考察了设计师对细节的极致追求和辨别力。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-7311-14"
  },
  {
    "role": "visual",
    "dimension": "维度八：AI结果辨别和优化能力",
    "question": "题目描述\n正在制作一张洋葱学园的“名师公开课”海报，需要将拍摄的洋葱真人老师照片合成到由 Midjourney 生成的“未来科技感教室”背景中。 为了解决光影不统一的问题，你使用了某种 AI 工具对画面进行了“重照亮 (Relighting)”处理，但结果导致老师的面部皮肤出现了严重的“塑料感”和“蜡像感”，毛孔细节全无。为了让画面恢复为商业级摄影质感，以下哪些处理手段是专业且有效的？",
    "options": [
      {
        "id": "A",
        "text": "将图片导入 即梦 (Jimeng) 的“人脸变清晰/面部修复”功能中，利用国产 AI 的算法优势，自动补全丢失的面部毛孔细节。"
      },
      {
        "id": "B",
        "text": "使用 Adobe Camera Raw (ACR) 滤镜，适度调高“纹理 (Texture)”和“颗粒 (Grain)”参数，并在高光区添加轻微的杂色，以模拟真实相机的感光噪点，打破“伪顺滑”。"
      },
      {
        "id": "C",
        "text": "在 Photoshop 中建立一个中性灰图层，通过“添加杂色”和“高反差保留”操作制作一个噪点层，并使用“柔光”模式叠加在老师面部，通过物理叠加的方式找回皮肤质感。"
      },
      {
        "id": "D",
        "text": "使用 醒图 (Xingtu)，套用“胶片复古”滤镜，利用滤镜自带的浓重色调直接覆盖掉面部的塑料感，快速出图。"
      }
    ],
    "correct": [
      "B",
      "C"
    ],
    "explanation": "\nB, C (正确 - 工业级质感重建)：\nB 选项 是摄影后期的标准技法。AI 生成图（或 AI 处理后的人像）本质上是“计算出来的像素”，缺乏真实光子撞击传感器产生的随机噪点。手动添加颗粒 (Grain) 和提升纹理 (Texture) 是消除“数码味/塑料感”的最核心手段。\nC 选项 是高阶合成技法。当 AI 把皮肤磨得太平时，直接叠加一层“物理噪点”或真实的“皮肤纹理贴图”，是唯一能让假人变回真人的物理手段。\nA (陷阱 - 负向优化)：\n为什么有迷惑性： 既然细节丢了，用“变清晰/修复”工具听起来非常对症。\n为什么错： 目前市面上绝大多数 AI 修复工具（包括佐糖、老照片修复等），其底层逻辑是GAN对抗网络，它们修复模糊的方式往往是“涂抹平滑”和“锐化边缘”。对于已经是“蜡像感”的图片，使用这些工具只会让皮肤变得更油腻、更假，完全无法生成真实的毛孔级物理纹理。\nD (陷阱 - 业余手段)：\n为什么有迷惑性： 手机修图软件的滤镜确实能改变质感，且操作简单。\n为什么错： 在商业海报交付中，这属于“破坏性编辑”。它虽然用色调盖住了瑕疵，但也破坏了原本设定的光影色彩规范（品牌色），且手机 App 导出的画质往往会被压缩，无法满足印刷或大屏展示的精度要求。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-25133-15"
  },
  {
    "role": "visual",
    "dimension": "维度一：习惯用AI解决问题的程度",
    "question": "题目描述\n你在制作一张真人老师的宣传海报时，发现老师提供的照片分辨率极低且背景杂乱。基于高效的 AI 解决习惯，以下哪些处理方式是合理的组合？",
    "options": [
      {
        "id": "A",
        "text": "使用 Magnific AI 或 Topaz Gigapixel 对人像进行无损放大和细节增强，提升面部清晰度。"
      },
      {
        "id": "B",
        "text": "使用 Photoshop 的“移除背景 (Remove Background)”或专门的抠图 AI (如 Clipdrop) 快速分离人像。"
      },
      {
        "id": "C",
        "text": "将低清人像放入 Midjourney，使用 /blend 指令混合一张高清明星照，生成一张全新的高清人脸代替原老师。"
      },
      {
        "id": "D",
        "text": "使用 Photoshop 的“创成式填充”根据画面光影自动生成适合的教室或书房背景，替换杂乱的原背景。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B, D (正确)：针对“低清”和“背景乱”两个具体问题，分别调用了“超分工具”、“抠图工具”和“生成式填充工具”，思路清晰且对症下药。\nC (陷阱 - 伦理/真实性问题)：宣传海报必须保证老师本人的真实性，使用混合明星脸虽然清晰但改变了人物身份，属于严重的职业错误。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-72808-1"
  },
  {
    "role": "visual",
    "dimension": "维度一：习惯用AI解决问题的程度",
    "question": "题目描述\n项目组紧急需要一套“二次元校园运动会”的活动主视觉，包含主海报、H5头图和一系列 3D 风格的体育器材图标。作为习惯使用 AI 解决问题的设计师，你会将 AI 介入到以下哪些工作环节中？",
    "options": [
      {
        "id": "A",
        "text": "灵感发散：使用 Midjourney 输入“anime sports festival, vibrant colors, dynamic composition”生成多张草图，快速确认构图和配色方案。"
      },
      {
        "id": "B",
        "text": "物料生成：利用 Tripo AI 或 Meshy 生成 3D 体育器材的粗模或多角度视图，辅助 3D 图标的绘制与渲染。"
      },
      {
        "id": "C",
        "text": "画面扩展：针对 H5 适配问题，使用即梦的“画布扩展 (Outpainting)”功能，智能补全画面背景以适应长屏手机。"
      },
      {
        "id": "D",
        "text": "最终交付：直接将 Midjourney 生成的图片作为最终成品交付给开发，不做任何分层处理或手动精修。"
      }
    ],
    "correct": [
      "A",
      "B",
      "C"
    ],
    "explanation": "\nA, B, C (正确)：体现了全链路 AI 赋能的习惯，从灵感（MJ）到素材（3D AI）再到适配（Outpainting），将 AI 融入了工作流的各个节点。\nD (陷阱 - 盲信幻觉)：AI 直出图通常不符合商用交付标准（分辨率、分层、细节瑕疵），直接交付属于不负责任的行为，且不符合工程化交付标准。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-26753-0"
  },
  {
    "role": "visual",
    "dimension": "维度五：用AI能涉及的领域",
    "question": "题目描述：\n市场部急需一段 5 秒的“洋葱君”二次元角色动态视频，用于抖音端午节活动预热，要求角色眨眼并挥手，背景有粒子浮动效果。动画组排期已满，作为视觉设计师，你手头只有一张画好的高保真静态主视觉（KV）图。以下哪个方案能最快速且低成本地完成该跨领域交付？",
    "options": [
      {
        "id": "A",
        "text": "打开 Doubao (豆包) 的视频生成模块，直接输入提示词“生成一段洋葱君眨眼挥手的二次元视频”，通过文字描述生成视频。"
      },
      {
        "id": "B",
        "text": "将 KV 图上传至 Jimeng (即梦)的“图生视频”模块，在提示词中描述“保持角色特征不变，眨眼，挥手，粒子浮动，二次元风格”，并将“运动幅度 (Motion)”参数设为适中，生成后导出视频。"
      },
      {
        "id": "C",
        "text": "在 Liblib (哩布哩布)上下载一个通用的“二次元动作 LoRA”模型，配合 ControlNet 的 OpenPose 插件，在 Stable Diffusion 中通过逐帧重绘（Batch Img2Img）的方式手动拼合 120 张图来制作视频。"
      },
      {
        "id": "D",
        "text": "使用 Live2D Cubism 编写脚本，通过手动拆解 PSD 图层并绑定骨骼物理运算，保证二次元角色不崩坏。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确)：Jimeng (即梦)是目前国产工具中在“图生视频”领域表现优秀的代表，能够让视觉设计师突破平面限制，快速产出短视频素材，符合“拓展设计领域”的维度考核。\nA (错误)：豆包不知道洋葱君造型细节\nC (错误)：过度设计型陷阱。使用 SD 逐帧重绘不仅工作量巨大（不仅要生成还要后期合成），而且极难控制帧间抖动（闪烁问题），对于“5秒短视频”需求而言，属于投入产出比极低的“伪工程化”方案。\nD (错误)：传统低效陷阱。虽然 Live2D 效果好，但学习成本极高且制作周期长，属于“拒绝 AI 提效”的传统手工业思维，不符合题目“快速且低成本”的要求。",
    "type": "single",
    "id": "visual-single-1769587483379-82480-9"
  },
  {
    "role": "visual",
    "dimension": "维度五：用AI能涉及的领域",
    "question": "题目描述\n运营团队给到一份“洋葱学园暑期夏令营”的落地页首屏需求，包含一段长达 500 字的枯燥活动介绍，并强制要求全部放在主视觉核心区域。作为视觉设计师，如果照单全收，画面将密密麻麻全是字，严重影响美感和转化率。为了在不写代码的前提下，利用 AI 拓展专业边界并解决这一矛盾，以下最佳方案是？",
    "options": [
      {
        "id": "A",
        "text": "通过豆包搭建智能体，让ai扮演“资深广告达人”，专门提炼营销活动内容，如‘1个冲击力标题 + 3个核心利益点’，字数控制在 50 字以内”。"
      },
      {
        "id": "B",
        "text": "将这 500 字直接复制到 即梦 (Jimeng)的提示词框中，并在后面加上“--text-layout perfect”等指令，让 AI 生图模型理解所有中文语义，生成一张文字排版精美无乱码的海报背景。"
      },
      {
        "id": "C",
        "text": "将 500 字文案投喂给即梦 (Jimeng)，使用“创意字形”模式，让 AI 自动将所有文字堆砌成“洋葱君”的剪影形状（Typography Art），认为这样既保留了运营要求的全量文字，又兼具了图形美感的视觉冲击力。"
      },
      {
        "id": "D",
        "text": "利用 豆包 (Doubao)编写一段复杂的 JavaScript 脚本，在首屏制作一个“自动滚动的 3D 文本云”特效，把 500 字全部塞进去动态展示，增加用户停留时长。"
      }
    ],
    "correct": [
      "A"
    ],
    "explanation": "\nA (正确 - 跨界赋能) C (错误 - 视觉形式主义)：虽然利用 AI 完成了高难度的创意排版，但将 500 字堆砌成图形会导致文字极难阅读（可读性差），核心营销信息被淹没在形式感中，属于为了设计牺牲业务目标的“自嗨”行为。 D (错误 - 技术堆砌)：典型的“过度工程化”。首屏 3 秒原则要求信息必须瞬间传达。做成复杂的动态文本云不仅增加了开发成本，还让用户抓不住重点（动效干扰阅读），反而会降低页面的转化率。 B (错误 - 工具误用)：目前让生图 AI 直接解决 500 字的复杂版式，是对工具能力的误解。",
    "type": "single",
    "id": "visual-single-1769587483379-47104-8"
  },
  {
    "role": "visual",
    "dimension": "维度九：AI工具使用灵活性",
    "question": "题目描述：\n运营团队发来一张横版（16:9）的“洋葱学园新学期”主视觉海报，背景是宏大的二次元校园场景。现在需要将其调整为竖版（9:16）的手机启动页，保留人物面部特征和主体构图不发生形变，仅对上下背景进行自然延伸。使用即梦 Jimeng时，以下哪个操作路径是最高效且效果最可控的？",
    "options": [
      {
        "id": "A",
        "text": "进入“图片生成”的图生图模式，上传原图，将宽高比设置为 9:16，提示词描述画面内容，为了保证相似度，将“重绘幅度 (Denoising Strength)”调至 0.05，让 AI 基于原图微调生成。"
      },
      {
        "id": "B",
        "text": "进入“智能画布 (Canvas)”板块，导入原图并将画布尺寸修改为 9:16，调整原图位置至中间，选中上下空白透明区域，输入提示词“anime school sky, ground”进行生成填充。"
      },
      {
        "id": "C",
        "text": "使用“人物参考 (Character Reference)”功能，上传原图中的人物截图作为参考，设置“强一致性”模式，配合相同的提示词重新生成一张 9:16 的竖版插画，以确保人物长相一致。"
      },
      {
        "id": "D",
        "text": "先使用“图像工具”中的“超清修复 (Upscale)”将原图分辨率放大 4 倍，利用高分辨率带来的冗余像素，直接在画面中心裁切出一张 9:16 的局部特写图，以保证清晰度。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确)：智能画布 (Canvas) / 扩图 (Outpainting) 是解决“构图延展”的标准解法。它的工作原理是保持原图核心区域完全不动，仅对空白区域进行像素计算和补全，能完美满足“不改变主体构图和特征”的要求。\nA (错误 - 变形与模糊)：图生图模式下，强制改变宽高比（从 16:9 变 9:16）通常会导致原图被拉伸变形或被 AI 强行裁剪。即使重绘幅度极低，AI 也会对原图像素进行重组，无法做到“严格保留不发生形变”。\nC (错误 - 重新生成)：“参考”功能本质上是生成一张全新的图片。虽然长相可能相似，但人物的姿态、光影细节、衣服褶皱以及背景的透视关系都会发生变化，无法满足运营对“主视觉海报”定稿素材的严谨性要求。\nD (错误 - 构图缺失)：放大裁切虽然清晰度够，但会丢失左右两侧的背景信息，导致画面变成只有人物的大头照或半身照，破坏了原海报“宏大校园场景”的氛围感，不属于“背景延伸”。",
    "type": "single",
    "id": "visual-single-1769587483379-80701-17"
  },
  {
    "role": "visual",
    "dimension": "维度九：AI工具使用灵活性",
    "question": "题目描述\n你需要设计一张“太空探索”主题的超宽幅 KV（主视觉），画面极其复杂，包含宇航员、复杂的空间站结构、远处的星云和前景的控制台。直接用 AI 生成往往构图混乱或细节丢失。灵活运用 AI 的最佳思路是？",
    "options": [
      {
        "id": "A",
        "text": "在 Midjourney 中设置超长宽高比（如 --ar 16:9），输入所有元素的描述，点击生成直到满意为止。"
      },
      {
        "id": "B",
        "text": "先用 AI 生成高质量的星云背景；再单独生成宇航员和空间站的高清素材；最后在 PS 中拼合，并用“创成式填充”融合光影接缝。"
      },
      {
        "id": "C",
        "text": "找一张类似的电影海报，用 Image to Image 功能降低重绘幅度，直接照搬其构图。"
      },
      {
        "id": "D",
        "text": "用 3D 软件搭建所有粗模，渲染出深度图，再用 ControlNet 严格控制生成，哪怕需要花费 3 天时间建模。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确 - 拆解思维)：将复杂问题（大场景 KV）拆解为简单子问题（背景+主体+前景），分别利用 AI 的优势生成高质量局部，最后人工整合。这是处理高难度商用图的必经之路。\nA (陷阱 - 赌博心态)：现有模型在处理过多元素和超宽构图时，很难兼顾所有细节和逻辑，“抽卡”效率极低。\nC (陷阱 - 版权风险)：过度依赖垫图可能导致构图侵权，且难以修改细节。\nD (陷阱 - 效率陷阱/过度设计)：虽然方法硬核，但对于 2D 视觉需求，全场景建模成本过高，丧失了 AI 提效的初衷。",
    "type": "single",
    "id": "visual-single-1769587483379-75851-16"
  },
  {
    "role": "visual",
    "dimension": "维度四：会几个AI工具",
    "question": "题目描述\n为了保持洋葱学园 IP 角色（如洋葱君、蛋蛋君）在不同画面中的形象统一，以下哪些 AI 操作技巧是有效的？",
    "options": [
      {
        "id": "A",
        "text": "在 Midjourney 中使用 --cref (Character Reference) 参数上传角色三视图，并调节 --cw (Character Weight) 来控制相似度。"
      },
      {
        "id": "B",
        "text": "在 Stable Diffusion 中训练专属的 LoRA (Low-Rank Adaptation) 模型，固定角色的特征。"
      },
      {
        "id": "C",
        "text": "依靠在 Prompt 中写极其详细的外貌描述词（如“blue hair, round glasses, yellow hoodie”）来控制，不使用任何图片参考。"
      },
      {
        "id": "D",
        "text": "使用 Photoshop 的“面部替换”类插件（如 SwapFace 甚至手动 PS），将标准脸贴到生成的身体上。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B (正确 - 原生AI解法)：这是目前主流 AI 绘图工具控制一致性的两种最核心方法（参考图 vs 模型训练）。\nD (正确 - 传统/混合解法)：在 AI 生成无法完美还原时，传统的“换脸/贴图”依然是保证 IP 绝对一致的有效手段。\nC (陷阱 - 概率玄学)：仅靠 Prompt 很难保证复杂 IP 角色的细节（如发型分叉、衣服花纹）在多张图中完全一致，是效率最低且不可控的方法。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-84208-7"
  },
  {
    "role": "visual",
    "dimension": "维度四：会几个AI工具",
    "question": "题目描述\n在制作一个复杂的“赛博朋克风洋葱校园”合成海报时，需要用到多种 AI 工具的特长。以下关于工具分工的描述，哪些是合理的？",
    "options": [
      {
        "id": "A",
        "text": "使用 Midjourney 生成整体的概念构图和风格化的背景素材（如霓虹灯街道）。"
      },
      {
        "id": "B",
        "text": "使用 Stable Diffusion 配合 ControlNet (Depth/Canny) 将洋葱君的 3D 模型精确融合到背景中，保持透视和光影一致。"
      },
      {
        "id": "C",
        "text": "使用 Photoshop (Firefly) 的“移除工具”和“创成式填充”来微调画面中的多余杂物或修复衔接不自然的区域。"
      },
      {
        "id": "D",
        "text": "使用 ChatGPT 的 DALL-E 3 来生成海报上的最终排版文字，因为它生成的汉字笔画完美且支持矢量编辑。"
      }
    ],
    "correct": [
      "A",
      "B",
      "C"
    ],
    "explanation": "\nA, B, C (正确)：合理分配了工具优势——MJ 负责审美和创意，SD 负责精准控制和融合，PS 负责局部修缮。\nD (陷阱 - 功能幻觉)：DALL-E 3 虽然能生成简单文字，但目前仍经常出错，且生成的文字是位图无法编辑，更不支持矢量导出，专业排版绝不能依赖它。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-1506-6"
  },
  {
    "role": "visual",
    "dimension": "维度三：影响他人对AI的重视程度",
    "question": "题目描述\n团队成员在使用 AI 绘图时经常出现“提示词写不好”或“风格不统一”的问题。你会利用 Coze (扣子) 或类似平台采取哪些措施？",
    "options": [
      {
        "id": "A",
        "text": "在 Coze 上搭建一个“洋葱学园风格生成器”Bot，预设好品牌专属的 Prompt 模板和参数，同事只需输入画面主体即可生成统一风格图片。"
      },
      {
        "id": "B",
        "text": "建立团队内部的 Prompt 知识库（如飞书文档），并定期举办“AI 最佳实践分享会”，复盘成功与失败案例。"
      },
      {
        "id": "C",
        "text": "建议团队避开 Coze 等自动化工具，坚持直接使用原生绘图界面（如豆包/即梦官网）。理由是 Bot 封装了参数会牺牲“灵活性”，设计师应保持对每一个参数的手动控制权。"
      },
      {
        "id": "D",
        "text": "将 Coze Bot 发布到团队工作群（如飞书/钉钉），让大家在聊天框中直接调用 AI 能力，降低使用门槛。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA,B,D (正确)：利用 Coze 搭建 Bot 并集成到 IM 工具，是目前国内团队最先进的“AI 封装与落地”方式，通过“参数固化”直接解决了风格不稳的痛点。 B (正确)：传统的知识管理与培训机制，也是必要的辅助手段。 C (陷阱 - 目标错位)： 题目的核心痛点是“风格不统一”和“门槛高”。虽然原生界面确实更灵活，但在企业标准化作业中，“灵活性”往往是导致风格混乱的根源。此时应优先追求“标准化（Bot）”而非“灵活性”。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-18089-4"
  },
  {
    "role": "visual",
    "dimension": "维度三：影响他人对AI的重视程度",
    "question": "题目描述\n业务部门对 AI 绘图存在版权顾虑，不敢在商业项目中使用。为了消除误解并推动 AI 的合规应用，你应该做哪些准备？",
    "options": [
      {
        "id": "A",
        "text": "收集并整理 Adobe Firefly、Midjourney 企业版等工具的官方版权条款（Service Terms），标红重点发给法务和业务方确认。"
      },
      {
        "id": "B",
        "text": "制定“AI 商业应用安全红线”，明确规定哪些图可以直接用（如无实指的背景肌理），哪些必须人工重绘（如核心 IP 形象、带有文字的标识）。"
      },
      {
        "id": "C",
        "text": "告诉业务方：“网上大家都在用，法不责众，只要我们不说是 AI 画的就没人知道。”"
      },
      {
        "id": "D",
        "text": "建议公司采购具有版权保障的 AI 图库或模型服务（如 Getty Images AI），用“付费买安全”的逻辑打消业务顾虑。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B, D (正确)：通过“法律条款背书”、“制定内部风控流程”和“采购合规工具”这三板斧，专业地解决版权顾虑。\nC (陷阱 - 法律盲区)：掩耳盗铃，极易给公司带来巨大的法律风险和舆论危机，是极其不专业的表现。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-59722-5"
  },
  {
    "role": "visual",
    "dimension": "维度六：利用AI赋能团队的能力",
    "question": "题目描述\n每到开学季，团队都要为全国 30 个省份制作风格统一但文案不同的“省份限定”海报。以往需要 3 人加班 2 天完成，现在作为 AI 提效负责人，为了最大化释放人力并保证质量，以下哪种方案是最佳的系统性解法？",
    "options": [
      {
        "id": "A",
        "text": "训练私有模型保证 30 张海报风格绝对统一，动员大家收集整理所有品牌插画素材，使用Stable Diffusion训练一个专属的 LoRA 模型，并配置 ComfyUI 工作流，由设计师操作出图。"
      },
      {
        "id": "B",
        "text": "利用Midjourney的矩阵提示词 (Permutation Prompts) 功能，编写包含 30 个省份的超长指令（如 `{Beijing, Shanghai...}`），通过一次性批量生成最终成品。"
      },
      {
        "id": "C",
        "text": "在Coze (扣子)中搭建自动化工作流，串联即梦 (Jimeng)的“参考图控制”能力以确保背景风格统一，用 PIL 库进行文字合成与排版，让运营团队只需输入省份名即可自助生成并下载最终海报。"
      },
      {
        "id": "D",
        "text": "在Figma 中通过figma make，将包含所有文案的 Excel 表格直接拖入画布，通过语义分析自动绘制包含洋葱君的矢量海报。"
      }
    ],
    "correct": [
      "C"
    ],
    "explanation": "\nC (正确 - 工具赋能)：D6 维度的核心是将“个人能力”转化为“团队能力”。通过 Coze 将“生图 (即梦) + 逻辑控制 + 排版合成 (Python)”的复杂链路封装成自动化工具 (Bot) 交付给下游（运营），实现了真正的无人值守与自助服务，是最高效的赋能方式。\nA (错误 - 投入产出比失衡)：典型的“大炮打蚊子”。对于一次性的活动海报，通过 AI 的“参考图控制”即可解决统一性问题，为此专门耗时数天训练 LoRA 模型是严重的资源浪费，且最终仍需设计师手动操作，未能赋能团队。\nB (错误 - 工具局限)：虽然 MJ V6 有文字生成能力，但对特定中文汉字（尤其是 30 个不同的地名）的准确率极低，且难以控制文字在画面中的固定位置，盲目追求“一键直出”会导致极高的抽卡和修图成本。\nD (错误 - 功能幻觉)：figma make无法自动绘制出洋葱君",
    "type": "single",
    "id": "visual-single-1769587483379-71251-10"
  },
  {
    "role": "visual",
    "dimension": "维度六：利用AI赋能团队的能力",
    "question": "题目描述\n团队里的新来的设计师经常写不出好的 Prompt，导致生成的二次元人物风格忽好忽坏。为了提升团队整体的产出稳定性，你应该？",
    "options": [
      {
        "id": "A",
        "text": "引入“工程化约束”机制，统一迁移至ComfyUI，并要求设计师搭建包含数十个节点的复杂工作流，利用 CLIP Text Encode 节点的权重算法来精确控制每一个词的去噪步数，保证产出质量。"
      },
      {
        "id": "B",
        "text": "建议使用网上的“万能提示词尾缀”，加上“8k, UHD, detailed texture，best quality”等描述用词，就能产出优质画面"
      },
      {
        "id": "C",
        "text": "建立一个团队共享的“Notion Prompt 词典”，将洋葱学园专用的风格词、负向词、参数配置标准化，并封装成“GPT 提示词生成器”机器人，供全员调用。"
      },
      {
        "id": "D",
        "text": "告诉大家多去 Civitai 网站看图，看得多了自然就会写了，属于个人悟性问题。"
      }
    ],
    "correct": [
      "C"
    ],
    "explanation": "\nC (正确 - 资产沉淀)：通过建立标准库（Prompt Dictionary）和工具化（GPT Bot），将个人的隐性知识转化为团队的显性资产，确保了团队产出的下限。\nA 对于“写不出好 Prompt”的新人来说，强制引入极高门槛的节点式工作流属于“高射炮打蚊子”。\nB 无效操作：高清，高质量等尾缀对二次元风格的控制没有帮助\nD (低效 - 放任自流)：缺乏系统的引导和培训，依赖个人悟性会导致团队产出极不稳定。",
    "type": "single",
    "id": "visual-single-1769587483379-44326-11"
  },
  {
    "role": "visual",
    "dimension": "维度九：AI工具使用灵活性",
    "question": "题目描述\n接到一个需求：设计一张“赛博朋克风格的洋葱君在火星表面烤红薯”的海报，要求既要有宏大的科幻感，又要充满生活气息的幽默感。面对这种反差极大的复杂需求，如何灵活运用 AI？",
    "options": [
      {
        "id": "A",
        "text": "直接在 Midjourney 输入所有关键词，只要不断抽卡，总能抽到理想画面。"
      },
      {
        "id": "B",
        "text": "拆解元素：分别生成“火星科幻背景”、“赛博朋克风的烤炉”、“洋葱君动作素材”。"
      },
      {
        "id": "C",
        "text": "风格融合：如果 AI 生成的红薯太写实，可以使用“风格迁移”或 Image-to-Image 配合手绘涂鸦，将其调整为二次元风格。"
      },
      {
        "id": "D",
        "text": "局部重绘：先生成一张满意的赛博朋克火星场景，然后用 Inpainting 功能在指定位置生成“烤红薯的摊位”，最后贴入洋葱君。"
      }
    ],
    "correct": [
      "B",
      "C",
      "D"
    ],
    "explanation": "\nB, C, D (正确)：体现了“拆解-融合-局部控制”的灵活思路。面对复杂逻辑，不依赖一键生成，而是分步击破。\nA (陷阱 - 赌博心态)：面对逻辑冲突（高科技+土味）的 Prompt，AI 的理解能力通常有限，直接生成成功率极低。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-30898-16"
  },
  {
    "role": "visual",
    "dimension": "维度九：AI工具使用灵活性",
    "question": "题目描述： 你需要为洋葱学园制作一张“中国航天日”的主题海报，画面要求是：“洋葱君身穿专业宇航服，站在火星表面，背景是长征五号火箭发射的壮观场景”。以下哪些操作组合体现了对 AI 工具的灵活且专业的运用？",
    "options": [
      {
        "id": "A",
        "text": "知识库调用与提示词生成：先在 豆包 (Doubao)输入“长征五号火箭外观特征及配色”，获取准确的视觉描述，让 AI 将其转化为绘画提示词（Prompts），以确保生成的火箭结构准确。"
      },
      {
        "id": "B",
        "text": "IP 角色一致性控制：打开 即梦 (Jimeng) 的图片生成功能，上传洋葱君的标准三视图到“人物参考 (Character Reference)”区域，并配合文本描述“穿着白色宇航服”，锁定角色长相的同时精准控制服装特征。"
      },
      {
        "id": "C",
        "text": "为了方便后续排版，直接把生成的 JPG 图片上传给 豆包，输入指令“请把这张图转为分层清晰、文字可编辑的 PSD 源文件”，然后直接下载使用。"
      },
      {
        "id": "D",
        "text": "局部重绘与修复：如果生成的画面中火箭尾焰颜色不对，不重新生成整张图，而是使用 即梦 (Jimeng) 的“局部重绘 (Inpainting)”功能，涂抹尾焰区域并修改提示词为“blue flame”进行精准修正。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nC (错误 - 工具幻觉)：这是典型的“功能幻觉”。目前的 LLM (如豆包) 虽然支持多模态，但无法将一张扁平的 JPG 图片“逆向工程”还原为带完整图层、蒙版和矢量文字的 PSD 源文件。这需要专业的设计软件或特定插件，而非聊天机器人能直接完成。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-29418-17"
  },
  {
    "role": "visual",
    "dimension": "维度一：习惯用AI解决问题的程度",
    "question": "题目描述\n项目组紧急需要一张“洋葱君在未来太空城探索”的活动主视觉海报，你手头只有一个构图非常简陋的火柴人线稿草图。以下哪个工作流体现了最佳的 AI Native 解决习惯？",
    "options": [
      {
        "id": "A",
        "text": "将线稿上传至即梦 (Jimeng) 的“图生图”模式，配合“结构控制/边缘检测”功能锁定构图，利用豆包生成丰富细节的提示词，快速生成多张高完成度底图供选择。"
      },
      {
        "id": "B",
        "text": "将线稿上传给豆包 (Doubao) 的对话框，输入指令：“请帮我把这张线稿直接渲染成 3D 风格，导出 PSD 格式文件，要求图层独立可编辑”。"
      },
      {
        "id": "C",
        "text": "直接在即梦 (Jimeng) 中使用“文字生图”功能，输入“太空城、洋葱君”，依靠抽卡生成一张构图类似的图。"
      },
      {
        "id": "D",
        "text": "使用即梦 (Jimeng) 的“高清放大” (Upscale) 功能，将火柴人线稿直接放大 4 倍，用 AI 在放大过程中细节的补充变成真实的建筑和人物。"
      }
    ],
    "correct": [
      "A"
    ],
    "explanation": "A (正确 - 人机协作)：标准的高效 AI 工作流。利用豆包解决“提示词词穷”问题，利用即梦的图生图+控制能力解决“构图难控制”问题，体现了对不同 AI 工具长项的组合运用。 B (错误 - 功能幻觉)：目前的对话式 LLM（如豆包）主要处理文本/图片理解，无法直接生成复杂的、带图层逻辑的 PSD 工程文件，这是对 AI 能力边界的认知错误。 C (错误 - 放弃约束)：放弃已有的构图约束直接文生图，会导致生成结果不可控，增加了筛选成本，不符合“利用现有条件解决问题”的高效习惯。 D (错误 - 工具误用)：Upscale 功能的核心是增加像素密度和锐化边缘，虽然会有微弱的细节增加，但无法将简陋的“火柴人”直接“重绘”成复杂的场景，属于对工具原理的无知。",
    "type": "single",
    "id": "visual-single-1769587483379-56204-0"
  },
  {
    "role": "visual",
    "dimension": "维度一：习惯用AI解决问题的程度",
    "question": "题目描述\n运营需要在半小时内上线一组“期末冲刺”的活动 Banner，文案尚未确定，只给了“提分、焦虑、逆袭”几个关键词。作为视觉设计师，此时最高效的响应方式是？",
    "options": [
      {
        "id": "A",
        "text": "需要图文匹配，告知运营必须先在飞书文档中敲定最终文案，自己利用这段等待时间去花瓣网收集类似的竞品图，以免因文案变动导致设计返工。"
      },
      {
        "id": "B",
        "text": "直接在即梦 (Jimeng) 的提示词框中输入“精美二次元活动海报，画面正中心包含大大的‘期末提分’四个字”，利用 AI 的文生图功能一次性产出排版完美、字形准确的最终成品。"
      },
      {
        "id": "C",
        "text": "将关键词输入豆包 (Doubao)，要求其分析“考前焦虑心理学”，并生成一段 Python 代码，通过代码控制 Stable Diffusion 的 ControlNet 插件来精确生成人物的每一个微表情。"
      },
      {
        "id": "D",
        "text": "利用豆包 (Doubao) 根据关键词快速延展出 5-10 条短文案供运营确认，同时并发在即梦 (Jimeng) 中使用“参考图控制”生成符合洋葱风格的二次元留白背景图，最后在figma组合。"
      }
    ],
    "correct": [
      "D"
    ],
    "explanation": "D (正确 - 并行协作)：体现了 AI 时代的“并行工作流”习惯。利用 LLM (豆包) 解决文案灵感，利用 Image Gen (即梦) 解决素材生成，人工只需负责最后的组装，将串行工作变为并行，最大化利用了半小时。 A (错误 - 传统低效)：在敏捷开发和极速响应的场景下，被动等待文案是典型的传统线性工作流，缺乏利用 AI 进行“预判性生产”的主动性。 B (错误 - 能力边界)：虽然部分 AI 具备文字生成能力，但在半小时急需上线的情况下，AI 生成的文字排版、字体设计通常无法达到商用标准（易乱码、字体单一），盲信一键生成会导致反复抽卡浪费时间。 C (错误 - 技术堆砌)：典型的“高射炮打蚊子”。在半小时的紧急需求下，去搞心理学分析和编写代码，属于严重的过度工程化，脱离了“快速上线”的业务目标。",
    "type": "single",
    "id": "visual-single-1769587483379-36939-1"
  },
  {
    "role": "visual",
    "dimension": "维度五：用AI能涉及的领域",
    "question": "题目描述\n你需要为一段30秒的课程宣传视频制作分镜脚本（Storyboard）。虽然你不是专业的导演，但可以利用 AI 做什么？",
    "options": [
      {
        "id": "A",
        "text": "将课程大纲投喂给 ChatGPT，让它以“分镜描述、画面内容、景别、音效”为表头，输出一份详细的分镜脚本表格。"
      },
      {
        "id": "B",
        "text": "使用 Midjourney 按照 ChatGPT 生成的脚本描述，批量生成关键帧画面，拼成“动态分镜表 (Animatic)”给视频组参考。"
      },
      {
        "id": "C",
        "text": "使用即梦的“视频生成”功能，直接输入 Prompt 生成最终的 4K 高清成片。"
      },
      {
        "id": "D",
        "text": "使用 Suno 或 Udio 生成一段符合视频节奏的背景音乐 (BGM)，提供给剪辑师作为配乐参考。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B, D (正确)：利用 LLM 写脚本、利用 MJ 画分镜、利用 AI 生成音乐，完美展示了视觉设计师如何利用 AI 渗透到“视频导演”和“音频配乐”领域。\nC (陷阱 - 技术幻觉)：即梦虽然强大，但很难一次性生成时长30秒且逻辑严密、无需剪辑的最终成片，分镜环节不可省略。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-99959-9"
  },
  {
    "role": "visual",
    "dimension": "维度五：用AI能涉及的领域",
    "question": "题目描述\n洋葱学园要举办一场线下快闪活动，需要设计展台。作为视觉设计师，你可以如何利用 AI 跨界辅助空间/展陈设计？",
    "options": [
      {
        "id": "A",
        "text": "使用 即梦 (Jimeng) 生成“isometric view, exhibition booth design”等提示词，产出多张展台的概念效果图供搭建商参考风格。"
      },
      {
        "id": "B",
        "text": "利用 豆包 (Doubao) 分析活动的目标人群（中小学生），生成 5 个互动小游戏的创意方案，并让 AI 细化游戏规则。"
      },
      {
        "id": "C",
        "text": "将场地的尺寸数据发给 豆包 (Doubao)，指令其“生成尺寸标注的 CAD 施工图，以图片形式呈现”，发给工厂进行搭建，以节省绘图员成本。"
      },
      {
        "id": "D",
        "text": "使用 即梦 (Jimeng) 的视频生成功能，让平面的主视觉图产生“空间推拉”的运镜效果，用于现场大屏循环播放。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "A, B, D (正确)：分别涉及了“概念视觉参考”、“内容策划”和“多媒体物料”，这些都是 AI 擅长的创意与辅助领域。 C (陷阱 - 工具幻觉)： 这是设计类 AI 最典型的误区。目前的生成式 AI（特别是文生图/文生文）无法生成符合工业标准、尺寸精准的图片",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-34381-8"
  },
  {
    "role": "visual",
    "dimension": "维度七：用AI提升自身价值的能力",
    "question": "题目描述\n你原本只擅长平面海报设计，最近项目组想做“3D 盲盒风”的 IP 周边展示，但你不会 Blender 或 C4D。为了提升自身价值并拿下这个需求，拓展专业边界，以下最佳路径是？",
    "options": [
      {
        "id": "A",
        "text": "在 Midjourney 中输入提示词时添加 `--format .obj` 和 `--rigging true` 参数，利用其所谓的“多模态 3D 引擎”直接导出一份带骨骼绑定的 3D 源文件，以便后续还能做动画。"
      },
      {
        "id": "B",
        "text": "利用即梦 (Jimeng)的“图生图”功能控制三视图一致性，再配合Tripo AI等“图生 3D”工具生成初步模型 (GLB/OBJ)，最后导入Spline简单渲染，独立完成 80% 的高品质静态展示。"
      },
      {
        "id": "C",
        "text": "将 IP 的三视图上传给 豆包 (Doubao)，指令其编写 Python 脚本，通过在 Blender 中运行该脚本来“参数化生成”模型，认为这样能保证数学层面的完美几何结构，且不需要手动操作软件。"
      },
      {
        "id": "D",
        "text": "收集盲盒素材，在Liblib上训练一个专属的 LoRA 模型，生成几张“看起来像 3D”的平面图，给到负责三维的同时参考制作模型。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确 - 技能跃迁)：D7 维度的核心是利用 AI 工具链（Image Gen + 3D Gen）弥补硬技能（建模）的短板。通过“2D 生成 -> 3D 转化 -> 简易渲染”的 AI 工作流，设计师能在不掌握复杂建模软件的情况下，快速产出可交付的 3D 资产，极大地拓宽了个人能力边界和业务价值。\nA (错误 - 功能幻觉)：目前的图像生成工具 (如即梦/MJ) 主要输出位图，并不具备通过简单参数直接导出带骨骼绑定 (Rigging) 的专业 3D 源文件 (.obj/.fbx) 的能力。\nC (错误 - 伪极客陷阱)：虽然 LLM 可以写代码，但对于不懂 3D 拓扑结构和 Blender API 的设计师来说，试图通过纯代码生成复杂的 IP 角色模型是极度低效且几乎不可能成功的，这属于脱离实际的“技术幻想”。\nD (错误 - 低效)：高成本参考图",
    "type": "single",
    "id": "visual-single-1769587483379-38633-12"
  },
  {
    "role": "visual",
    "dimension": "维度七：用AI提升自身价值的能力",
    "question": "题目描述\n每次活动结束后，运营都会丢给你一堆 Excel 表格，里面是海报的点击数据。以前你只负责看一眼，现在为了转型为“数据驱动型设计师”，利用 AI 拓展专业深度，以下哪种做法最具实战价值？",
    "options": [
      {
        "id": "A",
        "text": "将 Excel 数据表上传至即梦，根据表中数据生成数据折线图，观测数据的同时还能作为炫酷海报，方便分享在相关飞书群"
      },
      {
        "id": "B",
        "text": "将Excel 数据（脱敏后）与点击率最高/最低的海报截图组合发送给豆包 (Doubao)，指令其扮演“视觉数据分析师”，对比分析共性，输出一份《视觉迭代策略建议书》。"
      },
      {
        "id": "C",
        "text": "利用即梦 (Jimeng) 的“文字特效”功能，将 Excel 里的枯燥数字直接生成为“火焰燃烧”或“液态金属”质感的 3D 艺术字，把数据展示得足够炫酷和具有设计感方便公司年会数据展示。"
      },
      {
        "id": "D",
        "text": "训练一个能预测点击率的专属“审美判官”，将公司核心业务数据（点击率、转化率、用户 ID）的 Excel 表格上传到开源在线模型训练平台通过“大炼丹”来寻找设计规律。"
      }
    ],
    "correct": [
      "B"
    ],
    "explanation": "\nB (正确 - 深度洞察)：D7 维度的核心是利用 AI 弥补设计师在“逻辑归纳”上的短板。通过多模态大模型（Vision 能力）将“视觉画面”与“业务数据”进行关联分析，产出可落地的设计方法论，这是从“美工”进阶为“策略型设计师”的关键路径。\nA (错误 - 工具误用)：即梦是视觉生成工具，不具备逻辑推理和数据分析能力。它无法“读懂”Excel 表格里的数字含义，更不可能根据数据趋势图自动生成海报，这是对 AI 原理的严重误解。\nC (错误 - 形式主义)：将精力花在“美化数据字体”上，属于典型的“为了设计而设计”。数据驱动的核心在于“发现规律”而非“装饰数字”，这种做法无法为业务带来实际增量。\nD (错误 - 合规雷区)：将包含用户隐私和商业机密的数据直接上传到不安全的公有/开源平台进行训练，属于严重的数据违规行为，极可能导致被开除。",
    "type": "single",
    "id": "visual-single-1769587483379-33158-13"
  },
  {
    "role": "visual",
    "dimension": "维度七：用AI提升自身价值的能力",
    "question": "题目描述\n年终汇报时，你想展示自己利用 AI 进行“数据化设计验证”的成果。以下哪些案例能体现这一价值？",
    "options": [
      {
        "id": "A",
        "text": "“我利用 Coze 搭建了自动化工作流，统计出本季度共生成了 5000 张素材，通过对比发现，AI 介入后的‘素材生产速率’同比提升了 800%，证明了设计产出的巨大价值。"
      },
      {
        "id": "B",
        "text": "“我试图利用 VisualEyes 或类似 AI 注意力热力图工具，在设计阶段预测了用户对海报的视觉焦点，并据此调整了标题位置，上线后点击率提升了 15%。”"
      },
      {
        "id": "C",
        "text": "“我把 A/B 测试的数据投喂给 ChatGPT，让它分析不同配色对转化率的影响，得出了‘暖色调在周末转化更高’的结论，并应用到了后续设计中。”"
      },
      {
        "id": "D",
        "text": "“在方案抉择阶段，我将两版草图上传给 豆包 (Doubao)，让它扮演‘挑剔的甲方’进行‘模拟审美评分’，并直接选择了得分较高的 9.5 分方案上线，省去了真实用户测试的时间。”"
      }
    ],
    "correct": [
      "B",
      "C"
    ],
    "explanation": "\nB, C (正确)：分别体现了“设计前测（热力图预测）”和“设计后验（数据归因分析）”，展示了用 AI 辅助科学决策的能力，极具含金量。\nA (陷阱 - 虚荣指标)： 这属于“生产效率指标” (Efficiency)，而非“设计验证指标”\nD (陷阱 - 伪科学)： LLM（大语言模型）的审美评分是基于概率的“幻觉评分”，代表不了真实用户的喜好。除非使用专门针对大量用户数据训练的“CTR 预测模型”（如 B 选项提到的工具），否则直接问聊天机器人“哪个好”纯属玄学",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-4007-13"
  },
  {
    "role": "visual",
    "dimension": "维度七：用AI提升自身价值的能力",
    "question": "题目描述\n你作为平面设计师，想利用 AI 学习并掌握“UI 界面设计”的能力，以便在未来能承接 App 改版需求。以下哪些学习路径是高效的？",
    "options": [
      {
        "id": "A",
        "text": "使用 Galileo AI 或 Uizard 等工具，输入文本描述生成 UI 原型，分析其布局逻辑和组件规范，反向学习设计系统。"
      },
      {
        "id": "B",
        "text": "利用 ChatGPT 作为“设计导师”，发送你的设计稿截图，让它从“用户体验 (UX)、视觉层级、WCAG 无障碍标准”等维度给出修改建议。"
      },
      {
        "id": "C",
        "text": "依然只看 Dribbble 上的美图，凭感觉模仿，不关注交互逻辑和规范。"
      },
      {
        "id": "D",
        "text": "用 Midjourney 生成酷炫的 UI 概念图（FUI），虽然无法落地开发，但可以用来提升审美和提取配色方案。"
      }
    ],
    "correct": [
      "A",
      "B",
      "D"
    ],
    "explanation": "\nA, B, D (正确)：通过 AI 生成原型学习逻辑 (A)、利用 AI 进行设计评审 (B)、利用 AI 获取灵感和配色 (D)，全方位辅助技能转型。\nC (陷阱 - 浅层模仿)：缺乏系统的学习方法，没有利用 AI 的分析和生成能力来深入理解 UI 设计的内核。",
    "type": "multiple",
    "id": "visual-multiple-1769587483379-92199-12"
  }
];